{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829ed005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2f5bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde5199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9050d980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: {question}\\n    \\n    Answer: Let us think in a stepwise manner\\n    \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = '''Question: {question}\n",
    "    \n",
    "    Answer: Let us think in a stepwise manner\n",
    "    \n",
    "'''\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e894edc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='Question: {question}\\n    \\n    Answer: Let us think in a stepwise manner\\n    \\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template,input_variables={'question'})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9024a763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(client=<InferenceClient(model='mistralai/Mixtral-8x7B-Instruct-v0.1', timeout=None)>, repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1', task='text-generation', model_kwargs={'temperature': 0.6, 'max_length': 200})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "                    model_kwargs={'temperature': 0.6, 'max_length': 200})\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90b25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which country is better? Germany or France?\n",
      "\n",
      "This is an impossible question to answer as both countries have their own unique qualities and strengths.\n",
      "\n",
      "Germany is known for its efficiency, strong economy, and advanced technology, while France is known for its rich culture, delicious food, and romantic atmosphere.\n",
      "\n",
      "In terms of quality of life, both countries offer a high standard of living, with excellent healthcare, education, and infrastructure. However, Germany tends to have a more structured and organized society, while France is known for\n"
     ]
    }
   ],
   "source": [
    "question = \"Which country is better? Germany or France\"\n",
    "\n",
    "print(llm.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e98eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a solar system?\n",
      "\n",
      "The solar system is made up of the Sun, the eight planets that orbit the Sun, the 100 or so moons of those planets, the asteroid belt, comets, and other icy bodies that are in orbit around the Sun. The solar system is located in a region of space called the Milky Way Galaxy, which is a spiral-shaped disk of stars and other matter. Our solar system is located about two-thirds of the way out from\n"
     ]
    }
   ],
   "source": [
    "question = \"What is a solar system?\"\n",
    "\n",
    "print(llm.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c07ff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some useful tips and strategies to excel in data science job interviews?\n",
      "\n",
      "1. Understand the job description: Before you start preparing for the interview, make sure you understand the job description and the skills required for the role. This will help you to focus your preparation on the most relevant topics.\n",
      "2. Brush up on your technical skills: Data science interviews often include technical questions that test your knowledge of statistics, machine learning, programming, and data visualization. Make sure you are familiar with the latest tools and techniques in these areas.\n",
      "3.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are some useful tips and strategies to excel in data science job interviews?\"\n",
    "\n",
    "print(llm.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
